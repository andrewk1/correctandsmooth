{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using PyG to implement and evaluate C&S on AsiaFM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing C&S and evaluating on AsiaFM Dataset\n",
        "\n",
        "In this Colab, we will load the AsiaFM dataset, test the performance of a simple MLP, and then refine our prediction results using [Correct&Smooth](https://arxiv.org/abs/2010.13993), a recently propose post-processing algorithm that can improve performance of baseline classifiers using graph structure.\n",
        "\n",
        "While the paper includes a codebase, this implementation is redone from scratch following the paper. It is centered around building the two main functions, _correct_, and _smooth_, then measuring and visualizing the performance on our dataset."
      ],
      "metadata": {
        "id": "PvPMUYwVAEK8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23WKzvFMGdat",
        "outputId": "7e4436c9-5eb4-487c-821e-5f2ac9081209"
      },
      "source": [
        "# Install required packages, following https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "%matplotlib inline\n",
        "import torch; torch.manual_seed(42);\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Graph-tools for visualization package (GraphViz)\n",
        "!echo \"deb http://downloads.skewed.de/apt bionic main\" >> /etc/apt/sources.list\n",
        "!apt-key adv --keyserver keys.openpgp.org --recv-key 612DEFB798507F25\n",
        "!apt-get update\n",
        "!apt-get install python3-graph-tool python3-cairo python3-matplotlib\n",
        "from graph_tool.all import *\n",
        "import graph_tool.draw as draw\n",
        "import matplotlib.cm as cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Executing: /tmp/apt-key-gpghome.QiDQejh6v0/gpg.1.sh --keyserver keys.openpgp.org --recv-key 612DEFB798507F25\n",
            "gpg: key 612DEFB798507F25: \"Tiago de Paula Peixoto <tiago@skewed.de>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://downloads.skewed.de/apt bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (107 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:52\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:52\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:53\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:53\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:52\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:52\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:53\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:53\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-cairo is already the newest version (1.16.2-1).\n",
            "python3-matplotlib is already the newest version (2.1.1-2ubuntu3).\n",
            "python3-graph-tool is already the newest version (2.43).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 82 not upgraded.\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:52\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:52\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:53\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:51 and /etc/apt/sources.list:53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3/dist-packages/graph_tool/draw/cairo_draw.py:32: RuntimeWarning: Error importing cairo. Graph drawing will not work.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/lib/python3/dist-packages/graph_tool/draw/cairo_draw.py:32: RuntimeWarning: Error importing cairo. Graph drawing will not work.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/lib/python3/dist-packages/graph_tool/draw/cairo_draw.py:32: RuntimeWarning: Error importing cairo. Graph drawing will not work.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/lib/python3/dist-packages/graph_tool/all.py:39: RuntimeWarning: Error importing draw module, proceeding nevertheless: No module named 'cairo._cairo'\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading datasets and preparing our graph visualizations\n",
        "\n",
        "We use the builtin LastFMAsia dataset in torch_geometric.datasets (although other datasets should work out of the box with this codebase as well). In a production setting, we would likely be pulling data out of a dataloader in PyTorch, but this data is sufficiently small that representing it as a dense matrix will suffice.\n",
        "\n",
        "Graph visualization in NetworkX is slow, so I've found the [graph-tool](https://graph-tool.skewed.de/) library and included [graphviz](https://graphviz.org/) bindings to be good for drawing. You will see some helper code in each cell below where we just load the new predictions into our graphviz representation and generate some new viz.\n",
        "\n",
        "DROP_EDGE_EXPERIMENT will test how C&S compares to other models when the graph is not as dense."
      ],
      "metadata": {
        "id": "8whszYp9YBwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z2YBxxQK5o4",
        "outputId": "6374838d-df4c-4ea1-e9f1-72aacfd772a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7fa6a9b3d6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGos1-ANKMvZ",
        "outputId": "9b7707ce-231e-4f41-8cbd-6b936ecb8bd1"
      },
      "source": [
        "\"\"\"\n",
        "Standard utility functionality to load and generate dataset splits\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from torch_geometric.datasets import Twitch, LastFMAsia\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "graph = LastFMAsia(\"./data\")  # Twitch(\"./data\", \"EN\")\n",
        "X = graph.data.x\n",
        "edge_index = graph.data.edge_index\n",
        "y = graph.data.y.squeeze()\n",
        "\n",
        "NUM_EDGE_KEEP = 0.3\n",
        "\n",
        "kept_edges = np.random.choice(edge_index.shape[1], int(edge_index.shape[1] * NUM_EDGE_KEEP))\n",
        "edge_index = edge_index[:, kept_edges]\n",
        "kept_nodes = list(set(edge_index.flatten().tolist()))\n",
        "\n",
        "# We use a 0.8 / 0.1 / 0.1 train/val/test split\n",
        "# For the last section of the blog post, we attempt an experiment with much\n",
        "# smaller data regime (0.5, 0.25, 0.25)\n",
        "SPLIT_FRACTIONS = (0.8,  0.1, 0.1)\n",
        "splits_sizes = (int(SPLIT_FRACTIONS[0] * len(X[kept_nodes])), \n",
        "                int(SPLIT_FRACTIONS[1] * len(X[kept_nodes])), \n",
        "                len(X[kept_nodes]) - int(SPLIT_FRACTIONS[0] * len(X[kept_nodes]))- int(SPLIT_FRACTIONS[1] * len(X[kept_nodes])))\n",
        "train_split, val_split, test_split = splits = torch.utils.data.random_split(X[kept_nodes], splits_sizes)\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test) = [(X[split.indices], y[split.indices]) for split in splits] \n",
        "\n",
        "num_labels = int(max(y) + 1)\n",
        "print(f\"Dataset: { X_train.shape[0] } training, { X_val.shape[0] } val, { X_test.shape[0] } test samples with { X.shape[1] } dim embeddings\")\n",
        "print(f\"{ edge_index.shape[1] } total followerships (edges)\")\n",
        "print(f\"{ num_labels } total classes\")\n",
        "\n",
        "# Building graph-tool Graph for visualization\n",
        "graph_tool_graph = Graph(directed=False)\n",
        "graph_tool_nodes = []\n",
        "\n",
        "# We add properties to each graph node that can then be visualized\n",
        "v_country = graph_tool_graph.new_vertex_property(\"int\")\n",
        "v_splits = graph_tool_graph.new_vertex_property(\"int\")\n",
        "for i in range(len(X)):\n",
        "    v = graph_tool_graph.add_vertex()\n",
        "    v_country[v] = y[i]\n",
        "    if i in train_split.indices:\n",
        "        v_splits[v] = 0\n",
        "    elif i in val_split.indices:\n",
        "        v_splits[v] = 1\n",
        "    elif i in test_split.indices:\n",
        "        v_splits[v] = 2\n",
        "    graph_tool_nodes.append(v)\n",
        "graph_tool_graph.vertex_properties[\"country\"] = v_country\n",
        "graph_tool_graph.vertex_properties[\"split\"] = v_splits\n",
        "\n",
        "for e in edge_index.T:\n",
        "    n1, n2 = [graph_tool_nodes[int(x)] for x in list(e)]\n",
        "    graph_tool_graph.add_edge(n1, n2)\n",
        "\n",
        "pos = draw.graphviz_draw(graph_tool_graph, \n",
        "                   output=\"home_country_gt.png\", \n",
        "                   overlap=False, \n",
        "                   size=(30, 30), \n",
        "                   vsize=0.3, \n",
        "                   vcolor=v_country)\n",
        "\n",
        "draw.graphviz_draw(graph_tool_graph, \n",
        "                   pos=pos,\n",
        "                   pin=True,\n",
        "                   output=\"splits.png\", \n",
        "                   overlap=False, \n",
        "                   size=(30, 30), \n",
        "                   vsize=0.3, \n",
        "                   vcolor=v_splits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 5179 training, 647 val, 648 test samples with 128 dim embeddings\n",
            "22244 total followerships (edges)\n",
            "18 total classes\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VertexPropertyMap object with value type 'vector<double>', for Graph 0x7fa6a340dd50, at 0x7fa6a81dbcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We form the normalized adjancency matrix for future use here."
      ],
      "metadata": {
        "id": "ysD__Ap1ZSh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Form normalized adjacency matrix S = D^(-1/2)AD^(-1/2)\n",
        "print(\"Form normalized adjacency matrix S...\")\n",
        "\n",
        "# Form the dense graph\n",
        "A = to_dense_adj(edge_index).squeeze()\n",
        "D = torch.diag(A.sum(-1))\n",
        "D_inv_sqrt = D.pow(-0.5)\n",
        "\n",
        "# Numerical errors from divide by 0, \n",
        "# we follow the correction from the paper codebase at:\n",
        "# https://github.com/CUAI/CorrectAndSmooth/blob/b910314a59270984f5e249462ee3faa815fc9a0c/outcome_correlation.py#L77\n",
        "D_inv_sqrt[D_inv_sqrt == float('inf')] = 0 # \n",
        "S = D_inv_sqrt @ A @ D_inv_sqrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FhDLqETViwO",
        "outputId": "1f2c7009-0b02-4b57-a4f7-67c24d1107c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Form normalized adjacency matrix S...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Training a base predictor\n",
        "The first step is to acquire a base classifier model that can output a probability distribution over the classes. We train a shallow MLP in PyTorch:"
      ],
      "metadata": {
        "id": "BVEcDuaGZeal"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzLa9_XhMHCn"
      },
      "source": [
        "class BasePredictor(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A simple MLP class to serve as the base predictor\n",
        "    \"\"\"\n",
        "    def __init__(self, n_hidden_layers=1, in_size=128, hidden_size=64, out_size=1):\n",
        "        super(BasePredictor, self).__init__()\n",
        "        if n_hidden_layers == 0:\n",
        "            self.net = torch.nn.Linear(in_size, out_size)\n",
        "        else:\n",
        "            net  = [torch.nn.Linear(in_size, hidden_size), torch.nn.ReLU()]\n",
        "            net += [torch.nn.Linear(hidden_size, hidden_size), torch.nn.ReLU()] * (n_hidden_layers - 1)\n",
        "            net += [torch.nn.Linear(hidden_size, out_size)]\n",
        "            self.net = torch.nn.Sequential(*net)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.net(X)\n",
        "        return out.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MLP achieves ~70% accuracy on the validation and test set. While nodes deep in each class cluster are consistent, the model makes errors on users with friends in different countries (cluster borders). You can see this in `home_country_mlp_pred.png`"
      ],
      "metadata": {
        "id": "7I-kIfBuZnLC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWZo8iLiMTdq",
        "outputId": "547414b2-bd7e-410e-f07b-c91edae641b1"
      },
      "source": [
        "\"\"\"\n",
        "Step 1: Training the base predictor using the per-node embeddings\n",
        "\"\"\"\n",
        "net = BasePredictor(in_size=X.shape[1], n_hidden_layers=1, out_size=num_labels)\n",
        "if num_labels > 1:\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "else:\n",
        "    loss = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "\n",
        "def train(X, y):\n",
        "    optimizer.zero_grad()\n",
        "    yhat = net(X)\n",
        "    l = loss(yhat, y)\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    return l\n",
        "\n",
        "NUM_EPOCHS = 500\n",
        "\n",
        "pbar = tqdm(range(NUM_EPOCHS))\n",
        "for ep in pbar:\n",
        "    l = train(X_train, y_train)\n",
        "    pred = torch.argmax(net(X_val), -1)\n",
        "    pbar.set_postfix({'loss': float(l), \"val_acc\": float(torch.sum(pred == y_val) / len(pred))})\n",
        "\n",
        "# Visualize the MLP predictions on validation and test sets\n",
        "pred_labels = torch.argmax(net(X), -1)\n",
        "v_country_mlp_pred = graph_tool_graph.new_vertex_property(\"int\")\n",
        "for i, v in enumerate(graph_tool_nodes):\n",
        "    v_country_mlp_pred[v] = pred_labels[i]\n",
        "\n",
        "# graph_tool_graph.vertex_properties[\"mlp_pred\"] = v_country_mlp_pred\n",
        "\n",
        "# draw.graphviz_draw(graph_tool_graph, \n",
        "#                    output=\"home_country_mlp_pred.png\", \n",
        "#                    pos=pos,\n",
        "#                    pin=True,\n",
        "#                    overlap=False, \n",
        "#                    size=(30, 30), \n",
        "#                    vsize=0.3, \n",
        "#                    vcolor=v_country_mlp_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:06<00:00, 76.99it/s, loss=0.411, val_acc=0.7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Correct\n",
        "\n",
        "We first form a matrix with each row equal to the residual error between the (one-hot encoded) labels `Y` and the predicted class distributions `Z` for the training nodes only (by setting the error at val and test indices to 0)."
      ],
      "metadata": {
        "id": "qnazB7xzZv3F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A8PeSlbWvCH"
      },
      "source": [
        "\"\"\"\n",
        "Step 2 (2.2): Correcting for error in base predictions with residual propagation\n",
        "\"\"\"\n",
        "Z = torch.softmax(net(X), -1)\n",
        "Y = F.one_hot(y, num_labels)\n",
        "\n",
        "def residual_error(Z):\n",
        "    \"\"\"\n",
        "    Form E, residual error matrix Z - L for training data\"\n",
        "    \"\"\"\n",
        "    E = Z - Y\n",
        "    E[val_split.indices + test_split.indices] = 0\n",
        "    return E\n",
        "\n",
        "E = residual_error(Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we \"smooth\" the error across the graph in `correct(...)`. Due to homophily, we expect errors to be positively correlated for neighboring nodes, so for validation/test nodes, errors on neighboring training nodes can be predictive of the real error.\n",
        "\n",
        "After smoothing the error, C&S scales the size of the new errors to be in the same scale as the original training errors in `autoscale(..)`. Adding the residuals back to the original predictions give us a new prediction vector Zr."
      ],
      "metadata": {
        "id": "1OF_mGlmaRTr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9LWblaRZI_G",
        "outputId": "4ff988f8-f47e-47af-e0d3-bbfa0dfa4ae4"
      },
      "source": [
        "def correct(E, alpha1 = 0.8, eps = 1e-5, verbose=True, viz=False):\n",
        "    \"\"\"\n",
        "\n",
        "    E^(t+1) = (1-alpha1)E + alpha * S @ E^(t) -> Ehat\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        pbar = tqdm(total=float('inf'))\n",
        "\n",
        "    Ehat = E\n",
        "    diff = eps\n",
        "    itr = 0\n",
        "    while diff >= eps:\n",
        "        # This is the iterative update step\n",
        "        Et = (1 - alpha1) * E + alpha1 * (S @ Ehat)\n",
        "        diff = float(torch.norm(Ehat - Et))\n",
        "        Ehat = Et\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({ 'diff': diff })\n",
        "\n",
        "        if viz and itr % 10 == 0:\n",
        "            v_Zr = graph_tool_graph.new_vertex_property(\"float\")\n",
        "            max_err = torch.max(Ehat, -1).values\n",
        "            for i, v in enumerate(graph_tool_nodes):\n",
        "                v_Zr[v] = max_err[i]\n",
        "\n",
        "            graph_tool_graph.vertex_properties[\"Zr\"] = v_Zr\n",
        "\n",
        "            draw.graphviz_draw(graph_tool_graph, \n",
        "                                output=f\"zr_e_{itr}.png\", \n",
        "                                pos=pos,\n",
        "                                pin=True,\n",
        "                                overlap=False, \n",
        "                                size=(30, 30), \n",
        "                                vsize=0.3, \n",
        "                                vcolor=v_Zr,\n",
        "                                vcmap=cm.get_cmap(\"inferno\")\n",
        "                               )\n",
        "        itr += 1\n",
        "    return Ehat\n",
        "\n",
        "Ehat = correct(E, viz=False)\n",
        "\n",
        "\n",
        "def autoscale(E, Ehat, Z):\n",
        "    \"\"\"\n",
        "    sigma = sum of absolute value of E for each training sample / num training samples\n",
        "    \"\"\"\n",
        "    sigma = float(sum(torch.norm(E[train_split.indices], p=1, dim=-1))) / len(train_split)\n",
        "    Zr = Z + sigma * Ehat / sum(abs(Ehat))\n",
        "    Zr[train_split.indices] = Z[train_split.indices]\n",
        "    return Zr\n",
        "\n",
        "Zr = autoscale(E, Ehat, Z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:00,  8.24it/s]\u001b[A\n",
            "1it [00:00,  8.24it/s, diff=30.6]\u001b[A\n",
            "2it [00:00,  7.31it/s, diff=30.6]\u001b[A\n",
            "2it [00:00,  7.31it/s, diff=11.7]\u001b[A\n",
            "3it [00:00,  6.62it/s, diff=11.7]\u001b[A\n",
            "3it [00:00,  6.62it/s, diff=6.38]\u001b[A\n",
            "4it [00:00,  7.08it/s, diff=6.38]\u001b[A\n",
            "4it [00:00,  7.08it/s, diff=4.03]\u001b[A\n",
            "5it [00:00,  6.20it/s, diff=4.03]\u001b[A\n",
            "5it [00:00,  6.20it/s, diff=2.84]\u001b[A\n",
            "6it [00:00,  5.63it/s, diff=2.84]\u001b[A\n",
            "6it [00:00,  5.63it/s, diff=2.13]\u001b[A\n",
            "7it [00:01,  4.32it/s, diff=2.13]\u001b[A\n",
            "7it [00:01,  4.32it/s, diff=1.64]\u001b[A\n",
            "8it [00:01,  4.49it/s, diff=1.64]\u001b[A\n",
            "8it [00:01,  4.49it/s, diff=1.28]\u001b[A\n",
            "9it [00:01,  5.26it/s, diff=1.28]\u001b[A\n",
            "9it [00:01,  5.26it/s, diff=1.01]\u001b[A\n",
            "10it [00:01,  5.26it/s, diff=0.796]\u001b[A\n",
            "11it [00:01,  7.22it/s, diff=0.796]\u001b[A\n",
            "11it [00:01,  7.22it/s, diff=0.632]\u001b[A\n",
            "12it [00:01,  7.22it/s, diff=0.502]\u001b[A\n",
            "13it [00:01,  8.57it/s, diff=0.502]\u001b[A\n",
            "13it [00:01,  8.57it/s, diff=0.4]  \u001b[A\n",
            "14it [00:02,  8.57it/s, diff=0.319]\u001b[A\n",
            "15it [00:02,  9.73it/s, diff=0.319]\u001b[A\n",
            "15it [00:02,  9.73it/s, diff=0.255]\u001b[A\n",
            "16it [00:02,  9.73it/s, diff=0.203]\u001b[A\n",
            "17it [00:02, 10.19it/s, diff=0.203]\u001b[A\n",
            "17it [00:02, 10.19it/s, diff=0.162]\u001b[A\n",
            "18it [00:02, 10.19it/s, diff=0.13] \u001b[A\n",
            "19it [00:02, 10.85it/s, diff=0.13]\u001b[A\n",
            "19it [00:02, 10.85it/s, diff=0.104]\u001b[A\n",
            "20it [00:02, 10.85it/s, diff=0.0828]\u001b[A\n",
            "21it [00:02, 11.37it/s, diff=0.0828]\u001b[A\n",
            "21it [00:02, 11.37it/s, diff=0.0662]\u001b[A\n",
            "22it [00:02, 11.37it/s, diff=0.0529]\u001b[A\n",
            "23it [00:02, 11.67it/s, diff=0.0529]\u001b[A\n",
            "23it [00:02, 11.67it/s, diff=0.0423]\u001b[A\n",
            "24it [00:02, 11.67it/s, diff=0.0338]\u001b[A\n",
            "25it [00:02, 11.57it/s, diff=0.0338]\u001b[A\n",
            "25it [00:02, 11.57it/s, diff=0.0271]\u001b[A\n",
            "26it [00:03, 11.57it/s, diff=0.0216]\u001b[A\n",
            "27it [00:03, 11.94it/s, diff=0.0216]\u001b[A\n",
            "27it [00:03, 11.94it/s, diff=0.0173]\u001b[A\n",
            "28it [00:03, 11.94it/s, diff=0.0138]\u001b[A\n",
            "29it [00:03, 12.11it/s, diff=0.0138]\u001b[A\n",
            "29it [00:03, 12.11it/s, diff=0.0111]\u001b[A\n",
            "30it [00:03, 12.11it/s, diff=0.00885]\u001b[A\n",
            "31it [00:03, 12.27it/s, diff=0.00885]\u001b[A\n",
            "31it [00:03, 12.27it/s, diff=0.00708]\u001b[A\n",
            "32it [00:03, 12.27it/s, diff=0.00566]\u001b[A\n",
            "33it [00:03, 12.32it/s, diff=0.00566]\u001b[A\n",
            "33it [00:03, 12.32it/s, diff=0.00453]\u001b[A\n",
            "34it [00:03, 12.32it/s, diff=0.00362]\u001b[A\n",
            "35it [00:03, 12.37it/s, diff=0.00362]\u001b[A\n",
            "35it [00:03, 12.37it/s, diff=0.0029] \u001b[A\n",
            "36it [00:03, 12.37it/s, diff=0.00232]\u001b[A\n",
            "37it [00:03, 12.26it/s, diff=0.00232]\u001b[A\n",
            "37it [00:03, 12.26it/s, diff=0.00185]\u001b[A\n",
            "38it [00:04, 12.26it/s, diff=0.00148]\u001b[A\n",
            "39it [00:04, 11.88it/s, diff=0.00148]\u001b[A\n",
            "39it [00:04, 11.88it/s, diff=0.00119]\u001b[A\n",
            "40it [00:04, 11.88it/s, diff=0.000949]\u001b[A\n",
            "41it [00:04, 11.99it/s, diff=0.000949]\u001b[A\n",
            "41it [00:04, 11.99it/s, diff=0.000759]\u001b[A\n",
            "42it [00:04, 11.99it/s, diff=0.000608]\u001b[A\n",
            "43it [00:04, 12.23it/s, diff=0.000608]\u001b[A\n",
            "43it [00:04, 12.23it/s, diff=0.000486]\u001b[A\n",
            "44it [00:04, 12.23it/s, diff=0.000389]\u001b[A\n",
            "45it [00:04, 12.47it/s, diff=0.000389]\u001b[A\n",
            "45it [00:04, 12.47it/s, diff=0.000311]\u001b[A\n",
            "46it [00:04, 12.47it/s, diff=0.000249]\u001b[A\n",
            "47it [00:04, 12.54it/s, diff=0.000249]\u001b[A\n",
            "47it [00:04, 12.54it/s, diff=0.000199]\u001b[A\n",
            "48it [00:04, 12.54it/s, diff=0.000159]\u001b[A\n",
            "49it [00:04, 12.75it/s, diff=0.000159]\u001b[A\n",
            "49it [00:04, 12.75it/s, diff=0.000127]\u001b[A\n",
            "50it [00:04, 12.75it/s, diff=0.000102]\u001b[A\n",
            "51it [00:05, 12.54it/s, diff=0.000102]\u001b[A\n",
            "51it [00:05, 12.54it/s, diff=8.15e-5] \u001b[A\n",
            "52it [00:05, 12.54it/s, diff=6.52e-5]\u001b[A\n",
            "53it [00:05, 12.69it/s, diff=6.52e-5]\u001b[A\n",
            "53it [00:05, 12.69it/s, diff=5.22e-5]\u001b[A\n",
            "54it [00:05, 12.69it/s, diff=4.18e-5]\u001b[A\n",
            "55it [00:05, 12.58it/s, diff=4.18e-5]\u001b[A\n",
            "55it [00:05, 12.58it/s, diff=3.34e-5]\u001b[A\n",
            "56it [00:05, 12.58it/s, diff=2.67e-5]\u001b[A\n",
            "57it [00:05, 12.40it/s, diff=2.67e-5]\u001b[A\n",
            "57it [00:05, 12.40it/s, diff=2.14e-5]\u001b[A\n",
            "58it [00:05, 12.40it/s, diff=1.71e-5]\u001b[A\n",
            "59it [00:05, 12.47it/s, diff=1.71e-5]\u001b[A\n",
            "59it [00:05, 12.47it/s, diff=1.37e-5]\u001b[A\n",
            "60it [00:05, 12.47it/s, diff=1.1e-5] \u001b[A\n",
            "61it [00:05, 12.51it/s, diff=1.1e-5]\u001b[A\n",
            "61it [00:05, 10.41it/s, diff=8.8e-6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Smooth\n",
        "In the Correct step, we smoothed errors over adjacent nodes. In the Smooth step, we will also smooth the predictions across adjacent nodes following the same intuition. The smoothing operation is identical to the error correction, this time iterating over our best guess matrix G, initialized to our scaled prediction vector."
      ],
      "metadata": {
        "id": "mNb_MxHWakbX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PF1dw5QMa1O",
        "outputId": "cd1eebee-79c3-4ab0-d4c9-d1d93280e546"
      },
      "source": [
        "\"\"\"\n",
        "Step 3: Smoothing final predictions with prediction correlation\n",
        "\"\"\"\n",
        "# Best guesses G:\n",
        "# validation and test it is Zr\n",
        "G = Zr\n",
        "G[train_split.indices] = Y[train_split.indices].type(torch.float32)\n",
        "\n",
        "def smooth(G, alpha2=0.8, eps=1e-5, verbose=True, viz=False):\n",
        "    # G^(t+1) = (1 - alpha)G + alpha2 SG^(t) -> Yhat\n",
        "    if verbose:\n",
        "        pbar = tqdm(total=float('inf'))\n",
        "\n",
        "    yhat = G\n",
        "    diff = eps\n",
        "    itr = 0\n",
        "    while diff >= eps:\n",
        "        Gt = (1 - alpha2) * G + alpha2 * (S @ yhat)\n",
        "        diff = float(torch.norm(yhat - Gt))\n",
        "        yhat = Gt\n",
        "        if verbose:\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({ 'diff': diff })\n",
        "        if viz and itr % 10 == 0:\n",
        "            preds = torch.argmax(yhat, -1)\n",
        "            v_yhat = graph_tool_graph.new_vertex_property(\"int\")\n",
        "            for i, v in enumerate(graph_tool_nodes):\n",
        "                v_yhat[v] = preds[i]\n",
        "\n",
        "            graph_tool_graph.vertex_properties[\"smooth\"] = v_yhat\n",
        "\n",
        "            draw.graphviz_draw(graph_tool_graph, \n",
        "                                output=f\"yhat_smooth_{itr}.png\", \n",
        "                                pos=pos,\n",
        "                                pin=True,\n",
        "                                overlap=False, \n",
        "                                size=(30, 30), \n",
        "                                vsize=0.3, \n",
        "                                vcolor=v_yhat)\n",
        "        itr += 1\n",
        "    return yhat\n",
        "\n",
        "yhat = smooth(G, alpha2=0.7666, viz=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:00, 15.66it/s, diff=50.6]\u001b[A\n",
            "2it [00:00, 15.07it/s, diff=50.6]\u001b[A\n",
            "2it [00:00, 15.07it/s, diff=17.4]\u001b[A\n",
            "3it [00:00, 15.07it/s, diff=8.55]\u001b[A\n",
            "4it [00:00, 13.10it/s, diff=8.55]\u001b[A\n",
            "4it [00:00, 13.10it/s, diff=5.07]\u001b[A\n",
            "5it [00:00, 13.10it/s, diff=3.31]\u001b[A\n",
            "6it [00:00, 13.02it/s, diff=3.31]\u001b[A\n",
            "6it [00:00, 13.02it/s, diff=2.36]\u001b[A\n",
            "7it [00:00, 13.02it/s, diff=1.72]\u001b[A\n",
            "8it [00:00, 12.99it/s, diff=1.72]\u001b[A\n",
            "8it [00:00, 12.99it/s, diff=1.29]\u001b[A\n",
            "9it [00:00, 12.99it/s, diff=0.965]\u001b[A\n",
            "10it [00:00, 12.82it/s, diff=0.965]\u001b[A\n",
            "10it [00:00, 12.82it/s, diff=0.731]\u001b[A\n",
            "11it [00:00, 12.82it/s, diff=0.554]\u001b[A\n",
            "12it [00:00, 12.41it/s, diff=0.554]\u001b[A\n",
            "12it [00:00, 12.41it/s, diff=0.422]\u001b[A\n",
            "13it [00:01, 12.41it/s, diff=0.321]\u001b[A\n",
            "14it [00:01, 12.12it/s, diff=0.321]\u001b[A\n",
            "14it [00:01, 12.12it/s, diff=0.245]\u001b[A\n",
            "15it [00:01, 12.12it/s, diff=0.187]\u001b[A\n",
            "16it [00:01, 12.30it/s, diff=0.187]\u001b[A\n",
            "16it [00:01, 12.30it/s, diff=0.143]\u001b[A\n",
            "17it [00:01, 12.30it/s, diff=0.109]\u001b[A\n",
            "18it [00:01, 12.63it/s, diff=0.109]\u001b[A\n",
            "18it [00:01, 12.63it/s, diff=0.0837]\u001b[A\n",
            "19it [00:01, 12.63it/s, diff=0.064] \u001b[A\n",
            "20it [00:01, 12.64it/s, diff=0.064]\u001b[A\n",
            "20it [00:01, 12.64it/s, diff=0.049]\u001b[A\n",
            "21it [00:01, 12.64it/s, diff=0.0375]\u001b[A\n",
            "22it [00:01, 12.52it/s, diff=0.0375]\u001b[A\n",
            "22it [00:01, 12.52it/s, diff=0.0287]\u001b[A\n",
            "23it [00:01, 12.52it/s, diff=0.022] \u001b[A\n",
            "24it [00:01, 12.70it/s, diff=0.022]\u001b[A\n",
            "24it [00:01, 12.70it/s, diff=0.0169]\u001b[A\n",
            "25it [00:01, 12.70it/s, diff=0.0129]\u001b[A\n",
            "26it [00:02, 12.65it/s, diff=0.0129]\u001b[A\n",
            "26it [00:02, 12.65it/s, diff=0.00989]\u001b[A\n",
            "27it [00:02, 12.65it/s, diff=0.00758]\u001b[A\n",
            "28it [00:02, 12.67it/s, diff=0.00758]\u001b[A\n",
            "28it [00:02, 12.67it/s, diff=0.00581]\u001b[A\n",
            "29it [00:02, 12.67it/s, diff=0.00445]\u001b[A\n",
            "30it [00:02, 12.82it/s, diff=0.00445]\u001b[A\n",
            "30it [00:02, 12.82it/s, diff=0.00341]\u001b[A\n",
            "31it [00:02, 12.82it/s, diff=0.00261]\u001b[A\n",
            "32it [00:02, 12.83it/s, diff=0.00261]\u001b[A\n",
            "32it [00:02, 12.83it/s, diff=0.002]  \u001b[A\n",
            "33it [00:02, 12.83it/s, diff=0.00153]\u001b[A\n",
            "34it [00:02, 12.60it/s, diff=0.00153]\u001b[A\n",
            "34it [00:02, 12.60it/s, diff=0.00118]\u001b[A\n",
            "35it [00:02, 12.60it/s, diff=0.000902]\u001b[A\n",
            "36it [00:02, 12.61it/s, diff=0.000902]\u001b[A\n",
            "36it [00:02, 12.61it/s, diff=0.000691]\u001b[A\n",
            "37it [00:02, 12.61it/s, diff=0.00053] \u001b[A\n",
            "38it [00:02, 12.97it/s, diff=0.00053]\u001b[A\n",
            "38it [00:02, 12.97it/s, diff=0.000406]\u001b[A\n",
            "39it [00:03, 12.97it/s, diff=0.000311]\u001b[A\n",
            "40it [00:03, 12.75it/s, diff=0.000311]\u001b[A\n",
            "40it [00:03, 12.75it/s, diff=0.000238]\u001b[A\n",
            "41it [00:03, 12.75it/s, diff=0.000183]\u001b[A\n",
            "42it [00:03, 12.79it/s, diff=0.000183]\u001b[A\n",
            "42it [00:03, 12.79it/s, diff=0.00014] \u001b[A\n",
            "43it [00:03, 12.79it/s, diff=0.000108]\u001b[A\n",
            "44it [00:03, 12.88it/s, diff=0.000108]\u001b[A\n",
            "44it [00:03, 12.88it/s, diff=8.25e-5] \u001b[A\n",
            "45it [00:03, 12.88it/s, diff=6.32e-5]\u001b[A\n",
            "46it [00:03, 12.82it/s, diff=6.32e-5]\u001b[A\n",
            "46it [00:03, 12.82it/s, diff=4.85e-5]\u001b[A\n",
            "47it [00:03, 12.82it/s, diff=3.72e-5]\u001b[A\n",
            "48it [00:03, 12.79it/s, diff=3.72e-5]\u001b[A\n",
            "48it [00:03, 12.79it/s, diff=2.85e-5]\u001b[A\n",
            "49it [00:03, 12.79it/s, diff=2.18e-5]\u001b[A\n",
            "50it [00:03, 12.79it/s, diff=2.18e-5]\u001b[A\n",
            "50it [00:03, 12.79it/s, diff=1.67e-5]\u001b[A\n",
            "51it [00:04, 12.79it/s, diff=1.27e-5]\u001b[A\n",
            "52it [00:04, 12.71it/s, diff=1.27e-5]\u001b[A\n",
            "52it [00:04, 12.68it/s, diff=9.76e-6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paper makes it clear the hyperparameter tuning is pretty vital to this method. We implement a simple sweep here that just does a grid search in sequence. Serious implementations should look at parallelizing this search over a wider space."
      ],
      "metadata": {
        "id": "UZ5W0FMAayxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import linspace\n",
        "net.train(False)\n",
        "\n",
        "def correct_and_smooth(E, Z, y, alpha1=0.4, alpha2=0.4):\n",
        "    \"\"\"\n",
        "    Full pipeline for C&S\n",
        "    \"\"\"\n",
        "    Ehat = correct(E, alpha1=alpha1, verbose=False, eps=1e-4)\n",
        "    G = autoscale(E, Ehat, Z)\n",
        "    G[train_split.indices] = Y[train_split.indices].type(torch.float32)\n",
        "    yhat = smooth(G, alpha2=alpha2, verbose=False, eps=1e-4)\n",
        "    return yhat\n",
        "\n",
        "def hyperparameter_sweep(model, X, y, alpha1s, alpha2s):\n",
        "    \"\"\"\n",
        "    We test val accuracy over a grid search of alpha1 and alpha2 and return\n",
        "    the results as a list of (val_acc, (alpha1, alpha2)) for each run.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    Z = torch.sigmoid(model(X))\n",
        "    E = residual_error(Z)\n",
        "    with tqdm(total=len(alpha1s) * len(alpha2s)) as pbar:\n",
        "        for alpha1 in alpha1s:\n",
        "            for alpha2 in alpha2s:\n",
        "                yhat = correct_and_smooth(E, Z, y, alpha1, alpha2)\n",
        "                pred = torch.argmax(yhat, -1)\n",
        "                val_acc = torch.mean((pred[val_split.indices] == y[val_split.indices]).type(torch.float32))\n",
        "                results.append([float(val_acc), (alpha1, alpha2), yhat])\n",
        "                pbar.update(1)\n",
        "    return results\n",
        "\n",
        "\n",
        "alpha1s, alpha2s = linspace(0.1, 0.9, 5), linspace(0.1, 0.9, 5)\n",
        "sweep = sorted(hyperparameter_sweep(net, X, y, alpha1s, alpha2s))\n",
        "display(f\"Max val acc: { sweep[-1][0] } with hparams: { sweep[-1][1] }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "vgbC3zcn-_IO",
        "outputId": "4ba44e85-8824-4a32-d1cc-befafe843344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "403it [00:43, 14.66it/s, diff=1.35e-6]\n",
            "  8%|▊         | 2/25 [00:01<00:21,  1.06it/s]\u001b[A\n",
            " 12%|█▏        | 3/25 [00:03<00:26,  1.22s/it]\u001b[A\n",
            " 16%|█▌        | 4/25 [00:05<00:35,  1.70s/it]\u001b[A\n",
            " 20%|██        | 5/25 [00:12<01:13,  3.66s/it]\u001b[A\n",
            " 24%|██▍       | 6/25 [00:14<00:52,  2.78s/it]\u001b[A\n",
            " 28%|██▊       | 7/25 [00:15<00:41,  2.32s/it]\u001b[A\n",
            " 32%|███▏      | 8/25 [00:17<00:36,  2.15s/it]\u001b[A\n",
            " 36%|███▌      | 9/25 [00:19<00:37,  2.35s/it]\u001b[A\n",
            " 40%|████      | 10/25 [00:27<00:59,  3.94s/it]\u001b[A\n",
            " 44%|████▍     | 11/25 [00:29<00:44,  3.21s/it]\u001b[A\n",
            " 48%|████▊     | 12/25 [00:30<00:36,  2.78s/it]\u001b[A\n",
            " 52%|█████▏    | 13/25 [00:33<00:31,  2.61s/it]\u001b[A\n",
            " 56%|█████▌    | 14/25 [00:36<00:30,  2.77s/it]\u001b[A\n",
            " 60%|██████    | 15/25 [00:43<00:42,  4.29s/it]\u001b[A\n",
            " 64%|██████▍   | 16/25 [00:46<00:33,  3.75s/it]\u001b[A\n",
            " 68%|██████▊   | 17/25 [00:49<00:27,  3.43s/it]\u001b[A\n",
            " 72%|███████▏  | 18/25 [00:52<00:23,  3.34s/it]\u001b[A\n",
            " 76%|███████▌  | 19/25 [00:56<00:21,  3.56s/it]\u001b[A\n",
            " 80%|████████  | 20/25 [01:05<00:25,  5.13s/it]\u001b[A\n",
            " 84%|████████▍ | 21/25 [01:12<00:22,  5.74s/it]\u001b[A\n",
            " 88%|████████▊ | 22/25 [01:19<00:18,  6.26s/it]\u001b[A\n",
            " 92%|█████████▏| 23/25 [01:27<00:13,  6.73s/it]\u001b[A\n",
            " 96%|█████████▌| 24/25 [01:36<00:07,  7.40s/it]\u001b[A\n",
            "100%|██████████| 25/25 [01:50<00:00,  4.42s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Max val acc: 0.7743431329727173 with hparams: (0.9, 0.9)'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here below we summarize our model performance results. With each step, we see nearly 10% jump in accuracy! Clearly, there are huge gains to be had in including the graph structure in this particular predictive task. We also see the importance of the two alpha variables to the performance of the smoothing steps - run a hyperparameter sweep if you choose to implement this method!"
      ],
      "metadata": {
        "id": "Utzx45LxbFL9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wPhdrArOIvz",
        "outputId": "41cb525e-cce6-4ba3-9bb7-a164906f972e"
      },
      "source": [
        "yhat_mlp = torch.argmax(net(X), -1)\n",
        "print(f\"Val  accuracy MLP: { torch.mean((yhat_mlp[val_split.indices] == y[val_split.indices]).type(torch.float32)) }\")\n",
        "print(f\"Test accuracy MLP: { torch.mean((yhat_mlp[test_split.indices] == y[test_split.indices]).type(torch.float32)) }\\n\")\n",
        "\n",
        "yhat_correct = torch.argmax(G, -1)\n",
        "print(f\"Val  accuracy Correct: { torch.mean((yhat_correct[val_split.indices] == y[val_split.indices]).type(torch.float32)) }\")\n",
        "print(f\"Test accuracy Correct: { torch.mean((yhat_correct[test_split.indices] == y[test_split.indices]).type(torch.float32)) }\\n\")\n",
        "\n",
        "yhat_cs = torch.argmax(correct_and_smooth(E, Z, y), -1)\n",
        "print(f\"Val  accuracy Correct&Smooth: { torch.mean((yhat_cs[val_split.indices] == y[val_split.indices]).type(torch.float32)) }\")\n",
        "print(f\"Test accuracy Correct&Smooth: { torch.mean((yhat_cs[test_split.indices] == y[test_split.indices]).type(torch.float32)) }\\n\")\n",
        "\n",
        "yhat_cs_sweep = torch.argmax(sorted(sweep)[-1][2], -1)\n",
        "print(f\"Val  accuracy Correct&Smooth Sweep: { torch.mean((yhat_cs_sweep[val_split.indices] == y[val_split.indices]).type(torch.float32)) }\")\n",
        "print(f\"Test accuracy Correct&Smooth Sweep: { torch.mean((yhat_cs_sweep[test_split.indices] == y[test_split.indices]).type(torch.float32)) }\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val  accuracy MLP: 0.7001545429229736\n",
            "Test accuracy MLP: 0.6975308656692505\n",
            "\n",
            "Val  accuracy Correct: 0.7001545429229736\n",
            "Test accuracy Correct: 0.6975308656692505\n",
            "\n",
            "Val  accuracy Correct&Smooth: 0.7465224266052246\n",
            "Test accuracy Correct&Smooth: 0.7577160596847534\n",
            "\n",
            "Val  accuracy Correct&Smooth Sweep: 0.7743431329727173\n",
            "Test accuracy Correct&Smooth Sweep: 0.8040123581886292\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explaining C&S\n",
        "A 20% increase in accuracy deserves some scrutiny - why does C&S perform so well here? Dense graphs lend themselves really well to classical smoothing approaches."
      ],
      "metadata": {
        "id": "FomfH9qmbUWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_simple = Y.clone().type(torch.float)\n",
        "Y_simple[val_split.indices + test_split.indices] = 0\n",
        "\n",
        "def simple_smooth(Y_simple, alpha_simple = 0.8, eps = 1e-5, verbose=True):\n",
        "    if verbose:\n",
        "        pbar = tqdm(total=float('inf'))\n",
        "\n",
        "    Yhat_simple = Y_simple\n",
        "    diff = eps\n",
        "    itr = 0\n",
        "    while diff >= eps:\n",
        "        # This is the iterative update step\n",
        "        Yhat_t = (1 - alpha_simple) * Y_simple + alpha_simple * (S @ Yhat_simple)\n",
        "        diff = float(torch.norm(Yhat_simple - Yhat_t))\n",
        "        Yhat_simple = Yhat_t\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({ 'diff': diff })\n",
        "\n",
        "    return Yhat_simple\n",
        "\n",
        "Yhat_simple = simple_smooth(Y_simple, verbose=False)\n",
        "yhat_simple_correct = torch.argmax(Yhat_simple, -1)\n",
        "print(f\"Val  accuracy Correct: { torch.mean((yhat_simple_correct[val_split.indices] == y[val_split.indices]).type(torch.float32)) }\")\n",
        "print(f\"Test accuracy Correct: { torch.mean((yhat_simple_correct[test_split.indices] == y[test_split.indices]).type(torch.float32)) }\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyhD-31fhk6R",
        "outputId": "33cebda4-5a9a-4502-df25-42cee4952c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val  accuracy Correct: 0.5950540900230408\n",
            "Test accuracy Correct: 0.6280864477157593\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D9jrbCw0BxGS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}